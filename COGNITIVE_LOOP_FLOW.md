# ADHDo Cognitive Loop - Complete Flow Documentation

## âœ… System Status: FULLY OPERATIONAL

The Claude V2 Cognitive Engine is working and making intelligent, context-aware decisions for ADHD support.

## ğŸ”„ Complete Cognitive Loop Flow

### 1. **User Input** â†’ `/claude/v2/chat` endpoint
- User sends message with their current state/need
- Example: "I have been coding for 3 hours and feel hyperfocused"

### 2. **State Gathering** (`StateGatherer.gather_complete_state()`)
The system collects comprehensive context from multiple sources:

#### Physical State:
- Steps today (from Google Fit)
- Last movement time
- Sitting duration  
- Hydration status

#### Temporal Context:
- Current time and day part
- Typical energy patterns
- Medication timing and effectiveness

#### Task State:
- Current focus activity
- Duration of current task
- Urgent/overdue tasks (from Google Tasks)
- Upcoming events (from Google Calendar)

#### Environment:
- Available devices (Nest speakers)
- Music playing status
- Ambient distractions

#### Historical Patterns:
- Recent ADHD patterns detected
- Previous decisions and outcomes
- Success rates

### 3. **Claude Decision Making** (`ClaudeCognitiveEngineV2.process()`)

Claude receives the complete state as a structured prompt and responds with JSON containing:

```json
{
  "reasoning": "Analytical explanation of the situation",
  "confidence": 0.0-1.0,
  "response_to_user": "Natural language message",
  "immediate_actions": [
    {
      "type": "action_type",
      "params": {...},
      "priority": "high/medium/low"
    }
  ],
  "state_updates": {
    "stress_level": "low/medium/high",
    "focus_state": "deep/shallow/recovering",
    "energy_trend": "rising/stable/falling"
  },
  "patterns_detected": ["hyperfocus", "time_blindness"],
  "prediction": {
    "next_need": "break/movement/hydration",
    "timeframe_minutes": 15,
    "confidence": 0.95
  }
}
```

### 4. **Action Execution** (`_execute_decision()`)

The system executes Claude's recommended actions through various subsystems:

#### Available Actions:

**Music Control** (`music_controller.py`):
- `play_music`: Start mood-specific music
- `stop_music`: Stop current playback
- `adjust_volume`: Change volume level

**Timer System** (`timer_system.py`):
- `set_timer`: Create work/break/medication timers
- `cancel_timer`: Stop active timers

**Nudge System** (`nest_nudges.py`):
- `send_nudge`: Immediate alerts via Nest devices
- `schedule_nudge`: Delayed reminders

**Task Management** (`task_manager.py`):
- `set_focus`: Update current focus task
- `mark_complete`: Complete tasks

**Environment Control**:
- `adjust_lights`: Modify lighting
- `reduce_distractions`: Minimize stimuli

**Pattern Logging**:
- `log_pattern`: Record ADHD patterns for learning

### 5. **Learning & Storage** (`_store_decision()`)

Each decision is stored with:
- Complete state snapshot
- Claude's reasoning and confidence
- Actions taken
- Actual outcomes
- User feedback

This data improves future decisions through pattern recognition.

## ğŸ“Š Real Example from Testing

**Input**: "I have been coding for 3 hours and feel hyperfocused"

**Claude's Decision**:
- **Reasoning**: "User has been in hyperfocus for 3 hours coding, which exceeds healthy sustained attention"
- **Confidence**: 0.9 (very high)
- **Patterns Detected**: ["hyperfocus", "time_blindness"]

**Actions Executed**:
1. âœ… Set 15-minute break timer
2. âœ… Play calm music on Nest Hub Max
3. âœ… Log hyperfocus pattern
4. âŒ Send nudge (parameter mismatch - minor bug)

**Predictions**:
- Next need: "movement" in 5 minutes (95% confidence)

## ğŸ—ï¸ System Architecture

```
User Message
    â†“
[Claude V2 Chat Endpoint]
    â†“
[State Gatherer]
    â”œâ”€â”€ Google Calendar API
    â”œâ”€â”€ Google Tasks API
    â”œâ”€â”€ Google Fit API
    â”œâ”€â”€ Redis Pattern Storage
    â””â”€â”€ Real-time Context
    â†“
[Claude Cognitive Engine V2]
    â”œâ”€â”€ Browser Automation
    â”œâ”€â”€ Prompt Construction
    â””â”€â”€ JSON Response Parsing
    â†“
[Action Executor]
    â”œâ”€â”€ Music Controller
    â”œâ”€â”€ Timer System
    â”œâ”€â”€ Nest Nudge System
    â”œâ”€â”€ Task Manager
    â””â”€â”€ Pattern Logger
    â†“
[Response to User]
    â””â”€â”€ Including reasoning, actions taken, and predictions
```

## ğŸ”§ Key Components

### Core Files:
- `minimal_main.py` - Main server entry point
- `claude_cognitive_engine_v2.py` - Decision engine
- `claude_browser_working.py` - Claude browser automation
- `google_integration.py` - Google services integration
- `nest_nudges.py` - Nest device control
- `timer_system.py` - Timer management
- `music_controller.py` - Music playback control

### Data Flow:
1. **Input Processing**: 2-3 seconds
2. **State Gathering**: 1-2 seconds  
3. **Claude Decision**: 30-45 seconds (browser automation)
4. **Action Execution**: 1-2 seconds
5. **Total Response Time**: ~40-50 seconds

## ğŸ¯ Success Metrics

- âœ… **Intelligent Decisions**: Claude analyzes context and makes appropriate recommendations
- âœ… **Pattern Detection**: Identifies ADHD patterns like hyperfocus, time blindness
- âœ… **Multi-Action Execution**: Orchestrates multiple interventions simultaneously
- âœ… **Predictive Capabilities**: Forecasts future needs with confidence scores
- âœ… **Graceful Degradation**: Falls back to defaults if Claude unavailable

## ğŸ› Known Issues (Minor)

1. **Nudge urgency parameter**: Needs mapping from Claude's "urgency" to system's expected format
2. **Response time**: 30-45 seconds due to browser automation (would be faster with API)
3. **Jellyfin music**: Requires Jellyfin server running for full music features

## ğŸš€ System is OPERATIONAL

The cognitive loop is fully functional and making intelligent decisions to support ADHD users through:
- Real-time state analysis
- Context-aware interventions
- Pattern recognition and learning
- Multi-modal support (timers, music, nudges)
- Predictive assistance

The system successfully demonstrates the Meta-Cognitive Protocol (MCP) architecture for ADHD executive function support.